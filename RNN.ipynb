{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9ZKbXs3MpFzQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "import argparse\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchtext\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_4iAL3nrcE4",
        "outputId": "59dcbeac-2c6f-4bce-a919-38f583ede96e"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipnTRok-pAKK",
        "outputId": "7a96121c-3b1f-44cd-c366-3a8153ea150c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /home/smruti/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /home/smruti/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "sw = stopwords.words('english') \n",
        "\n",
        "\n",
        "class Tokenizer:\n",
        "\n",
        "    def __init__(self, file, threshold=5):\n",
        "        self.file = file\n",
        "        self.data = pd.read_csv(file)\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def preprocess(self):\n",
        "        tokenizer = torchtext.data.utils.get_tokenizer('spacy', language='en')\n",
        "        tokens = []\n",
        "        sentence_list=[]\n",
        "        for text in self.data['text'].tolist():\n",
        "            tokens.append(tokenizer(text))\n",
        "            sentence_list.append(text.split('.'))\n",
        "\n",
        "        self.data['sentences_list'] = sentence_list\n",
        "        counter = Counter()\n",
        "        for line in tokens:\n",
        "            for word in line:\n",
        "                counter[word] += 1\n",
        "        # print(len(counter.items()), len(counter.most_common()))\n",
        "\n",
        "        # remove all words that have frequency less than threshold\n",
        "        # counter_threshold = {k:v for k,v in counter.items() if v >= self.threshold}\n",
        "\n",
        "        # create mappings\n",
        "        # mapper = {word:idx+1 for idx,word in enumerate(counter_threshold.keys())}\n",
        "        # inverse_mapper = {idx+1:word for idx,word in enumerate(counter_threshold.keys())}\n",
        "\n",
        "        # sos_idx = len(counter_threshold.keys())\n",
        "        # eos_idx = len(counter_threshold.keys()) + 1\n",
        "        # other_idx = len(counter_threshold.keys()) + 2\n",
        "\n",
        "        # mapped_tokens = []\n",
        "\n",
        "        # for line in tokens:\n",
        "        #     mapped_line = [sos_idx]\n",
        "        #     for word in line:\n",
        "        #       # map words to their mappings and to other otherwise\n",
        "        #         mapped_line.append(mapper.get(word, other_idx))\n",
        "        #     mapped_line.append(eos_idx)\n",
        "        #     mapped_tokens.append(mapped_line)\n",
        "\n",
        "        # inverse_mapper[other_idx] = \"__OTHER__\"\n",
        "        # inverse_mapper[sos_idx] = \"__SOS__\"\n",
        "        # inverse_mapper[eos_idx] = \"__EOS__\"\n",
        "        # inverse_mapper[0] = \"__PADDING__\"\n",
        "\n",
        "        mapper = {word[0]: idx+1 for idx,\n",
        "                  word in enumerate(counter.most_common())}\n",
        "        inverse_mapper = {idx+1: word[0] for idx,\n",
        "                          word in enumerate(counter.most_common())}\n",
        "\n",
        "        # sos_idx = len(counter_threshold.keys())\n",
        "        # eos_idx = len(counter_threshold.keys()) + 1\n",
        "        other_idx = len(counter.keys())\n",
        "\n",
        "        mapped_tokens = []\n",
        "\n",
        "        for line in tokens:\n",
        "            mapped_line = []\n",
        "            for word in line:\n",
        "              # map words to their mappings and to other otherwise\n",
        "                mapped_line.append(mapper.get(word, other_idx))\n",
        "            mapped_tokens.append(mapped_line)\n",
        "\n",
        "        # inverse_mapper[other_idx] = \"__OTHER__\"\n",
        "        # inverse_mapper[sos_idx] = \"__SOS__\"\n",
        "        # inverse_mapper[eos_idx] = \"__EOS__\"\n",
        "        # inverse_mapper[0] = \"__PADDING__\"\n",
        "\n",
        "        return mapped_tokens, inverse_mapper\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def similarity_paragraph(data):\n",
        "    # data = self.data\n",
        "    sim_list = []\n",
        "    for para in data['sentences_list'].tolist():\n",
        "      sim = 2000\n",
        "      start = para[0]\n",
        "      para = para[1:]\n",
        "      for sent in para:            \n",
        "        # tokenization\n",
        "        X_list = word_tokenize(start) \n",
        "        Y_list = word_tokenize(sent)\n",
        "          \n",
        "        # sw contains the list of stopwords\n",
        "        l1 =[];l2 =[]\n",
        "          \n",
        "        # remove stop words from the string\n",
        "        X_set = {w for w in X_list if not w in sw} \n",
        "        Y_set = {w for w in Y_list if not w in sw}\n",
        "          \n",
        "        # form a set containing keywords of both strings \n",
        "        rvector = X_set.union(Y_set) \n",
        "        for w in rvector:\n",
        "            if w in X_set: l1.append(1) # create a vector\n",
        "            else: l1.append(0)\n",
        "            if w in Y_set: l2.append(1)\n",
        "            else: l2.append(0)\n",
        "        c = 0\n",
        "          \n",
        "        # cosine formula \n",
        "        for i in range(len(rvector)):\n",
        "            c+= l1[i]*l2[i]\n",
        "        try:\n",
        "          cosine = c / float((sum(l1)*sum(l2))**0.5)\n",
        "          if sim > cosine:\n",
        "            sim=cosine\n",
        "          # sim += cosine\n",
        "        except:\n",
        "          sim += 0\n",
        "          \n",
        "        start = sent\n",
        "      \n",
        "      # sim = sim/(len(para)+1)\n",
        "      sim_list.append(sim)\n",
        "    \n",
        "    data['similarity'] = sim_list\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "\n",
        "          \n",
        "          # print(\"similarity: \", cosine)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6LRLl-EAOeCL"
      },
      "outputs": [],
      "source": [
        "# training data\n",
        "data1 = pd.read_csv('data/GCDC_Corpus_v2/GCDC_rerelease/Clinton_train.csv')\n",
        "data2 = pd.read_csv('data/GCDC_Corpus_v2/GCDC_rerelease/Yahoo_train.csv')\n",
        "data3 = pd.read_csv('data/GCDC_Corpus_v2/GCDC_rerelease/Yelp_train.csv')\n",
        "data4 = pd.read_csv('data/GCDC_Corpus_v2/GCDC_rerelease//Enron_train.csv')\n",
        "\n",
        "data5 = pd.read_csv('data/GCDC_Corpus_v2/GCDC_rerelease/Yahoo_test.csv')\n",
        "data6 = pd.read_csv('data/GCDC_Corpus_v2/GCDC_rerelease/Yelp_test.csv')\n",
        "data7 = pd.read_csv('data/GCDC_Corpus_v2/GCDC_rerelease/Enron_test.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "p0m7bl6PO1oL"
      },
      "outputs": [],
      "source": [
        "data = pd.concat([data1, data2, data3, data4, data5, data6, data7])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ixt94NWwP8Hi"
      },
      "outputs": [],
      "source": [
        "data.to_csv('data/GCDC_Corpus_v2/new_train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "AGJivFqTNcF6"
      },
      "outputs": [],
      "source": [
        "# train = Tokenizer(\"/content/gdrive/MyDrive/GCDC_rerelease/train.csv\")\n",
        "# test = Tokenizer(\"/content/gdrive/MyDrive/GCDC_rerelease/Yahoo_test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6HowKzJMQLOM"
      },
      "outputs": [],
      "source": [
        "train = Tokenizer(\"data/GCDC_Corpus_v2/new_train.csv\")\n",
        "test = Tokenizer(\"data/GCDC_Corpus_v2/GCDC_rerelease/Clinton_test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKh63JzxQteb",
        "outputId": "1ca6277f-82ac-487a-fb00-c6d15366be5e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4600"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train.data)\n",
        "# len(test.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yS39RPLu83j",
        "outputId": "12337718-bc89-4b8a-ceb6-c8e8ad27c8fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " ...\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "# lst=[]\n",
        "# for i in range(1000):\n",
        "#   if train.data['labelA'][i]==3:\n",
        "#     lst.append([0,0,1])\n",
        "#   elif train.data['labelA'][i]==2:\n",
        "#     lst.append([0,1,0])\n",
        "#   elif train.data['labelA'][i]==1:\n",
        "#     lst.append([1,0,0])\n",
        "\n",
        "# train.data['h_e']=lst\n",
        "\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "lst = array(train.data['labelA'])\n",
        "encoded = to_categorical(lst)\n",
        "print(encoded)\n",
        "# inverted = argmax(encoded[0])\n",
        "# print(inverted)\n",
        "\n",
        "# train.data['h_e'] = encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "rK2UhBczvhRW"
      },
      "outputs": [],
      "source": [
        "# lst=[]\n",
        "# for i in range(200):\n",
        "#   if test.data['labelA'][i]==3:\n",
        "#     lst.append([0,0,1])\n",
        "#   elif test.data['labelA'][i]==2:\n",
        "#     lst.append([0,1,0])\n",
        "#   elif test.data['labelA'][i]==1:\n",
        "#     lst.append([1,0,0])\n",
        "\n",
        "# test.data['h_e']=lst\n",
        "\n",
        "lst = array(test.data['labelA'])\n",
        "t_encoded = to_categorical(lst)\n",
        "# test.data['h_e'] = encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/smruti/.local/lib/python3.11/site-packages/torchtext/data/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
          ]
        }
      ],
      "source": [
        "from torchtext import data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ONuCV7pSqCTb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/smruti/.local/lib/python3.11/site-packages/torchtext/data/utils.py:105: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
            "  warnings.warn(\n",
            "/home/smruti/.local/lib/python3.11/site-packages/torchtext/data/utils.py:105: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "train_mapping, inv_train_mapping = train.preprocess()\n",
        "test_mapping, inv_test_mapping = test.preprocess()\n",
        "\n",
        "# train.data = similarity_paragraph(train.data)\n",
        "# test.data = similarity_paragraph(test.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 832
        },
        "id": "QqDO2UAwnFvA",
        "outputId": "bfccbc3d-4616-4da8-96a1-cb84c324efc0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text_id</th>\n",
              "      <th>subject</th>\n",
              "      <th>text</th>\n",
              "      <th>ratingA1</th>\n",
              "      <th>ratingA2</th>\n",
              "      <th>ratingA3</th>\n",
              "      <th>labelA</th>\n",
              "      <th>ratingM1</th>\n",
              "      <th>ratingM2</th>\n",
              "      <th>ratingM3</th>\n",
              "      <th>ratingM4</th>\n",
              "      <th>ratingM5</th>\n",
              "      <th>labelM</th>\n",
              "      <th>question_title</th>\n",
              "      <th>question</th>\n",
              "      <th>sentences_list</th>\n",
              "      <th>encoding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>C05796441_2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Cheryl:\\n\\nAre we in a good place to begin pap...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Cheryl:\\n\\nAre we in a good place to begin pa...</td>\n",
              "      <td>[527, 107, 15, 1437, 22, 10, 7, 75, 97, 4, 870...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>C05786430_1</td>\n",
              "      <td>Department of State</td>\n",
              "      <td>Our friend, General Joe Ballard owns The Raven...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Our friend, General Joe Ballard owns The Rave...</td>\n",
              "      <td>[398, 370, 3, 1247, 2174, 9568, 3569, 29, 9569...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>C05780653_3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Outstanding news! Miki Rakic called about 10 m...</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Outstanding news! Miki Rakic called about 10 ...</td>\n",
              "      <td>[14045, 626, 37, 14046, 19230, 253, 54, 355, 3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>C05782181_1</td>\n",
              "      <td>Libyan CG Pol Dirs mtg @ Istanbul @ 14:00 Thur...</td>\n",
              "      <td>Responding to separate emails from Uzra + Jeff...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Responding to separate emails from Uzra + Jef...</td>\n",
              "      <td>[19243, 4, 1518, 3177, 43, 14049, 1133, 581, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>C05785147_0</td>\n",
              "      <td>Mexico</td>\n",
              "      <td>Guy from Mexico is in NY and is cooperating. D...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Guy from Mexico is in NY and is cooperating, ...</td>\n",
              "      <td>[6125, 43, 1011, 12, 10, 1566, 5, 12, 6700, 1,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4595</th>\n",
              "      <td>195</td>\n",
              "      <td>1353855</td>\n",
              "      <td>Comments of Wolak</td>\n",
              "      <td>Wolak makes some good points.  In ERCOT, Enron...</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Wolak makes some good points,   In ERCOT, Enr...</td>\n",
              "      <td>[36543, 433, 72, 75, 555, 1, 9, 166, 2845, 3, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4596</th>\n",
              "      <td>196</td>\n",
              "      <td>1131834</td>\n",
              "      <td>NBC</td>\n",
              "      <td>The reason NBC will not take cash is the prefe...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[The reason NBC will not take cash is the pref...</td>\n",
              "      <td>[29, 404, 4399, 28, 26, 134, 642, 12, 2, 4060,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4597</th>\n",
              "      <td>197</td>\n",
              "      <td>725369</td>\n",
              "      <td>Gallup Peak</td>\n",
              "      <td>All GC's\\n\\nAfter utilizing the Gallup Peak Av...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[All GC's\\n\\nAfter utilizing the Gallup Peak A...</td>\n",
              "      <td>[360, 13660, 25, 15, 444, 18330, 2, 9777, 9551...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4598</th>\n",
              "      <td>198</td>\n",
              "      <td>766379</td>\n",
              "      <td>New TW Contract System</td>\n",
              "      <td>Lindy,\\n\\nJust wanted to let you know that we ...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Lindy,\\n\\nJust wanted to let you know that we...</td>\n",
              "      <td>[8276, 3, 15, 389, 202, 4, 179, 13, 68, 11, 22...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4599</th>\n",
              "      <td>199</td>\n",
              "      <td>1122541</td>\n",
              "      <td>UGGGHHHHH</td>\n",
              "      <td>I know, I know.  It's still weird to me.  Whil...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[I know, I know,   It's still weird to me,   W...</td>\n",
              "      <td>[6, 68, 3, 6, 68, 1, 9, 73, 25, 144, 1867, 4, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4600 rows × 18 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0      text_id  \\\n",
              "0              0  C05796441_2   \n",
              "1              1  C05786430_1   \n",
              "2              2  C05780653_3   \n",
              "3              3  C05782181_1   \n",
              "4              4  C05785147_0   \n",
              "...          ...          ...   \n",
              "4595         195      1353855   \n",
              "4596         196      1131834   \n",
              "4597         197       725369   \n",
              "4598         198       766379   \n",
              "4599         199      1122541   \n",
              "\n",
              "                                                subject  \\\n",
              "0                                                   NaN   \n",
              "1                                   Department of State   \n",
              "2                                                   NaN   \n",
              "3     Libyan CG Pol Dirs mtg @ Istanbul @ 14:00 Thur...   \n",
              "4                                                Mexico   \n",
              "...                                                 ...   \n",
              "4595                                  Comments of Wolak   \n",
              "4596                                                NBC   \n",
              "4597                                        Gallup Peak   \n",
              "4598                             New TW Contract System   \n",
              "4599                                          UGGGHHHHH   \n",
              "\n",
              "                                                   text  ratingA1  ratingA2  \\\n",
              "0     Cheryl:\\n\\nAre we in a good place to begin pap...         3         2   \n",
              "1     Our friend, General Joe Ballard owns The Raven...         2         1   \n",
              "2     Outstanding news! Miki Rakic called about 10 m...         2         3   \n",
              "3     Responding to separate emails from Uzra + Jeff...         1         2   \n",
              "4     Guy from Mexico is in NY and is cooperating. D...         2         1   \n",
              "...                                                 ...       ...       ...   \n",
              "4595  Wolak makes some good points.  In ERCOT, Enron...         2         3   \n",
              "4596  The reason NBC will not take cash is the prefe...         2         2   \n",
              "4597  All GC's\\n\\nAfter utilizing the Gallup Peak Av...         3         3   \n",
              "4598  Lindy,\\n\\nJust wanted to let you know that we ...         3         2   \n",
              "4599  I know, I know.  It's still weird to me.  Whil...         2         1   \n",
              "\n",
              "      ratingA3  labelA  ratingM1  ratingM2  ratingM3  ratingM4  ratingM5  \\\n",
              "0            1       2         2         2         3         1         2   \n",
              "1            3       2         3         2         3         1         3   \n",
              "2            3       3         2         2         3         2         3   \n",
              "3            1       1         2         2         1         3         1   \n",
              "4            1       1         1         1         2         3         1   \n",
              "...        ...     ...       ...       ...       ...       ...       ...   \n",
              "4595         2       3         2         2         2         2         2   \n",
              "4596         1       1         2         2         2         2         2   \n",
              "4597         3       3         3         2         2         3         2   \n",
              "4598         1       2         2         3         2         2         2   \n",
              "4599         2       1         1         2         1         1         2   \n",
              "\n",
              "      labelM question_title question  \\\n",
              "0          2            NaN      NaN   \n",
              "1          3            NaN      NaN   \n",
              "2          3            NaN      NaN   \n",
              "3          1            NaN      NaN   \n",
              "4          1            NaN      NaN   \n",
              "...      ...            ...      ...   \n",
              "4595       2            NaN      NaN   \n",
              "4596       2            NaN      NaN   \n",
              "4597       3            NaN      NaN   \n",
              "4598       2            NaN      NaN   \n",
              "4599       1            NaN      NaN   \n",
              "\n",
              "                                         sentences_list  \\\n",
              "0     [Cheryl:\\n\\nAre we in a good place to begin pa...   \n",
              "1     [Our friend, General Joe Ballard owns The Rave...   \n",
              "2     [Outstanding news! Miki Rakic called about 10 ...   \n",
              "3     [Responding to separate emails from Uzra + Jef...   \n",
              "4     [Guy from Mexico is in NY and is cooperating, ...   \n",
              "...                                                 ...   \n",
              "4595  [Wolak makes some good points,   In ERCOT, Enr...   \n",
              "4596  [The reason NBC will not take cash is the pref...   \n",
              "4597  [All GC's\\n\\nAfter utilizing the Gallup Peak A...   \n",
              "4598  [Lindy,\\n\\nJust wanted to let you know that we...   \n",
              "4599  [I know, I know,   It's still weird to me,   W...   \n",
              "\n",
              "                                               encoding  \n",
              "0     [527, 107, 15, 1437, 22, 10, 7, 75, 97, 4, 870...  \n",
              "1     [398, 370, 3, 1247, 2174, 9568, 3569, 29, 9569...  \n",
              "2     [14045, 626, 37, 14046, 19230, 253, 54, 355, 3...  \n",
              "3     [19243, 4, 1518, 3177, 43, 14049, 1133, 581, 1...  \n",
              "4     [6125, 43, 1011, 12, 10, 1566, 5, 12, 6700, 1,...  \n",
              "...                                                 ...  \n",
              "4595  [36543, 433, 72, 75, 555, 1, 9, 166, 2845, 3, ...  \n",
              "4596  [29, 404, 4399, 28, 26, 134, 642, 12, 2, 4060,...  \n",
              "4597  [360, 13660, 25, 15, 444, 18330, 2, 9777, 9551...  \n",
              "4598  [8276, 3, 15, 389, 202, 4, 179, 13, 68, 11, 22...  \n",
              "4599  [6, 68, 3, 6, 68, 1, 9, 73, 25, 144, 1867, 4, ...  \n",
              "\n",
              "[4600 rows x 18 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# new_data = open('/content/drive/MyDrive/GCDC_rerelease/mapped_tokens_Yelp_train.csv.pkl','rb')\n",
        "# new_t_data = open('/content/drive/MyDrive/GCDC_rerelease/mapped_tokens_Yelp_test.csv.pkl','rb')\n",
        "# train_mapping = pickle.load(new_data)\n",
        "# test_mapping = pickle.load(new_t_data)\n",
        "\n",
        "len(train_mapping)\n",
        "# train_mapping\n",
        "train.data['encoding'] = train_mapping\n",
        "test.data['encoding'] = test_mapping\n",
        "train.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 832
        },
        "id": "Lo-MrHNzvsJw",
        "outputId": "90a0b22a-851d-4db3-e2ac-594370c5f68e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text_id</th>\n",
              "      <th>subject</th>\n",
              "      <th>text</th>\n",
              "      <th>ratingA1</th>\n",
              "      <th>ratingA2</th>\n",
              "      <th>ratingA3</th>\n",
              "      <th>labelA</th>\n",
              "      <th>ratingM1</th>\n",
              "      <th>ratingM2</th>\n",
              "      <th>ratingM3</th>\n",
              "      <th>ratingM4</th>\n",
              "      <th>ratingM5</th>\n",
              "      <th>labelM</th>\n",
              "      <th>question_title</th>\n",
              "      <th>question</th>\n",
              "      <th>sentences_list</th>\n",
              "      <th>encoding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>C05796441_2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Cheryl:\\n\\nAre we in a good place to begin pap...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Cheryl:\\n\\nAre we in a good place to begin pa...</td>\n",
              "      <td>[527, 107, 15, 1437, 22, 10, 7, 75, 97, 4, 870...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>C05786430_1</td>\n",
              "      <td>Department of State</td>\n",
              "      <td>Our friend, General Joe Ballard owns The Raven...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Our friend, General Joe Ballard owns The Rave...</td>\n",
              "      <td>[398, 370, 3, 1247, 2174, 9568, 3569, 29, 9569...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>C05780653_3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Outstanding news! Miki Rakic called about 10 m...</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Outstanding news! Miki Rakic called about 10 ...</td>\n",
              "      <td>[14045, 626, 37, 14046, 19230, 253, 54, 355, 3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>C05782181_1</td>\n",
              "      <td>Libyan CG Pol Dirs mtg @ Istanbul @ 14:00 Thur...</td>\n",
              "      <td>Responding to separate emails from Uzra + Jeff...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Responding to separate emails from Uzra + Jef...</td>\n",
              "      <td>[19243, 4, 1518, 3177, 43, 14049, 1133, 581, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>C05785147_0</td>\n",
              "      <td>Mexico</td>\n",
              "      <td>Guy from Mexico is in NY and is cooperating. D...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Guy from Mexico is in NY and is cooperating, ...</td>\n",
              "      <td>[6125, 43, 1011, 12, 10, 1566, 5, 12, 6700, 1,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4595</th>\n",
              "      <td>195</td>\n",
              "      <td>1353855</td>\n",
              "      <td>Comments of Wolak</td>\n",
              "      <td>Wolak makes some good points.  In ERCOT, Enron...</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Wolak makes some good points,   In ERCOT, Enr...</td>\n",
              "      <td>[36543, 433, 72, 75, 555, 1, 9, 166, 2845, 3, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4596</th>\n",
              "      <td>196</td>\n",
              "      <td>1131834</td>\n",
              "      <td>NBC</td>\n",
              "      <td>The reason NBC will not take cash is the prefe...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[The reason NBC will not take cash is the pref...</td>\n",
              "      <td>[29, 404, 4399, 28, 26, 134, 642, 12, 2, 4060,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4597</th>\n",
              "      <td>197</td>\n",
              "      <td>725369</td>\n",
              "      <td>Gallup Peak</td>\n",
              "      <td>All GC's\\n\\nAfter utilizing the Gallup Peak Av...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[All GC's\\n\\nAfter utilizing the Gallup Peak A...</td>\n",
              "      <td>[360, 13660, 25, 15, 444, 18330, 2, 9777, 9551...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4598</th>\n",
              "      <td>198</td>\n",
              "      <td>766379</td>\n",
              "      <td>New TW Contract System</td>\n",
              "      <td>Lindy,\\n\\nJust wanted to let you know that we ...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Lindy,\\n\\nJust wanted to let you know that we...</td>\n",
              "      <td>[8276, 3, 15, 389, 202, 4, 179, 13, 68, 11, 22...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4599</th>\n",
              "      <td>199</td>\n",
              "      <td>1122541</td>\n",
              "      <td>UGGGHHHHH</td>\n",
              "      <td>I know, I know.  It's still weird to me.  Whil...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[I know, I know,   It's still weird to me,   W...</td>\n",
              "      <td>[6, 68, 3, 6, 68, 1, 9, 73, 25, 144, 1867, 4, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4600 rows × 18 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0      text_id  \\\n",
              "0              0  C05796441_2   \n",
              "1              1  C05786430_1   \n",
              "2              2  C05780653_3   \n",
              "3              3  C05782181_1   \n",
              "4              4  C05785147_0   \n",
              "...          ...          ...   \n",
              "4595         195      1353855   \n",
              "4596         196      1131834   \n",
              "4597         197       725369   \n",
              "4598         198       766379   \n",
              "4599         199      1122541   \n",
              "\n",
              "                                                subject  \\\n",
              "0                                                   NaN   \n",
              "1                                   Department of State   \n",
              "2                                                   NaN   \n",
              "3     Libyan CG Pol Dirs mtg @ Istanbul @ 14:00 Thur...   \n",
              "4                                                Mexico   \n",
              "...                                                 ...   \n",
              "4595                                  Comments of Wolak   \n",
              "4596                                                NBC   \n",
              "4597                                        Gallup Peak   \n",
              "4598                             New TW Contract System   \n",
              "4599                                          UGGGHHHHH   \n",
              "\n",
              "                                                   text  ratingA1  ratingA2  \\\n",
              "0     Cheryl:\\n\\nAre we in a good place to begin pap...         3         2   \n",
              "1     Our friend, General Joe Ballard owns The Raven...         2         1   \n",
              "2     Outstanding news! Miki Rakic called about 10 m...         2         3   \n",
              "3     Responding to separate emails from Uzra + Jeff...         1         2   \n",
              "4     Guy from Mexico is in NY and is cooperating. D...         2         1   \n",
              "...                                                 ...       ...       ...   \n",
              "4595  Wolak makes some good points.  In ERCOT, Enron...         2         3   \n",
              "4596  The reason NBC will not take cash is the prefe...         2         2   \n",
              "4597  All GC's\\n\\nAfter utilizing the Gallup Peak Av...         3         3   \n",
              "4598  Lindy,\\n\\nJust wanted to let you know that we ...         3         2   \n",
              "4599  I know, I know.  It's still weird to me.  Whil...         2         1   \n",
              "\n",
              "      ratingA3  labelA  ratingM1  ratingM2  ratingM3  ratingM4  ratingM5  \\\n",
              "0            1       2         2         2         3         1         2   \n",
              "1            3       2         3         2         3         1         3   \n",
              "2            3       3         2         2         3         2         3   \n",
              "3            1       1         2         2         1         3         1   \n",
              "4            1       1         1         1         2         3         1   \n",
              "...        ...     ...       ...       ...       ...       ...       ...   \n",
              "4595         2       3         2         2         2         2         2   \n",
              "4596         1       1         2         2         2         2         2   \n",
              "4597         3       3         3         2         2         3         2   \n",
              "4598         1       2         2         3         2         2         2   \n",
              "4599         2       1         1         2         1         1         2   \n",
              "\n",
              "      labelM question_title question  \\\n",
              "0          2            NaN      NaN   \n",
              "1          3            NaN      NaN   \n",
              "2          3            NaN      NaN   \n",
              "3          1            NaN      NaN   \n",
              "4          1            NaN      NaN   \n",
              "...      ...            ...      ...   \n",
              "4595       2            NaN      NaN   \n",
              "4596       2            NaN      NaN   \n",
              "4597       3            NaN      NaN   \n",
              "4598       2            NaN      NaN   \n",
              "4599       1            NaN      NaN   \n",
              "\n",
              "                                         sentences_list  \\\n",
              "0     [Cheryl:\\n\\nAre we in a good place to begin pa...   \n",
              "1     [Our friend, General Joe Ballard owns The Rave...   \n",
              "2     [Outstanding news! Miki Rakic called about 10 ...   \n",
              "3     [Responding to separate emails from Uzra + Jef...   \n",
              "4     [Guy from Mexico is in NY and is cooperating, ...   \n",
              "...                                                 ...   \n",
              "4595  [Wolak makes some good points,   In ERCOT, Enr...   \n",
              "4596  [The reason NBC will not take cash is the pref...   \n",
              "4597  [All GC's\\n\\nAfter utilizing the Gallup Peak A...   \n",
              "4598  [Lindy,\\n\\nJust wanted to let you know that we...   \n",
              "4599  [I know, I know,   It's still weird to me,   W...   \n",
              "\n",
              "                                               encoding  \n",
              "0     [527, 107, 15, 1437, 22, 10, 7, 75, 97, 4, 870...  \n",
              "1     [398, 370, 3, 1247, 2174, 9568, 3569, 29, 9569...  \n",
              "2     [14045, 626, 37, 14046, 19230, 253, 54, 355, 3...  \n",
              "3     [19243, 4, 1518, 3177, 43, 14049, 1133, 581, 1...  \n",
              "4     [6125, 43, 1011, 12, 10, 1566, 5, 12, 6700, 1,...  \n",
              "...                                                 ...  \n",
              "4595  [36543, 433, 72, 75, 555, 1, 9, 166, 2845, 3, ...  \n",
              "4596  [29, 404, 4399, 28, 26, 134, 642, 12, 2, 4060,...  \n",
              "4597  [360, 13660, 25, 15, 444, 18330, 2, 9777, 9551...  \n",
              "4598  [8276, 3, 15, 389, 202, 4, 179, 13, 68, 11, 22...  \n",
              "4599  [6, 68, 3, 6, 68, 1, 9, 73, 25, 144, 1867, 4, ...  \n",
              "\n",
              "[4600 rows x 18 columns]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "tFqqpNYJvtIc",
        "outputId": "fc14eacb-a03f-45ab-f8d6-11d30f10becc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_id</th>\n",
              "      <th>subject</th>\n",
              "      <th>text</th>\n",
              "      <th>ratingA1</th>\n",
              "      <th>ratingA2</th>\n",
              "      <th>ratingA3</th>\n",
              "      <th>labelA</th>\n",
              "      <th>ratingM1</th>\n",
              "      <th>ratingM2</th>\n",
              "      <th>ratingM3</th>\n",
              "      <th>ratingM4</th>\n",
              "      <th>ratingM5</th>\n",
              "      <th>labelM</th>\n",
              "      <th>sentences_list</th>\n",
              "      <th>encoding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C05760125_1</td>\n",
              "      <td>Hilda Solis Tom and Craig--</td>\n",
              "      <td>Madame Secretary:\\n\\nThank you for reaching ou...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>[Madame Secretary:\\n\\nThank you for reaching o...</td>\n",
              "      <td>[1046, 44, 37, 7, 320, 16, 14, 2848, 77, 4, 44...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C05768263_2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Cheryl, Jake,\\n\\nI received a call from Masood...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>[Cheryl, Jake,\\n\\nI received a call from Masoo...</td>\n",
              "      <td>[199, 3, 183, 3, 7, 11, 560, 9, 123, 33, 2877,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C05771873_1</td>\n",
              "      <td>Framing Statement - State Draft</td>\n",
              "      <td>We anticipate the release of what are claimed ...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>[We anticipate the release of what are claimed...</td>\n",
              "      <td>[43, 2883, 1, 1061, 6, 78, 26, 1365, 4, 19, 40...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>C05768528_2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Spoke to Ed Levine today to follow up on Frida...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>[Spoke to Ed Levine today to follow up on Frid...</td>\n",
              "      <td>[2904, 4, 495, 2905, 82, 4, 445, 63, 13, 490, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>C05775052_1</td>\n",
              "      <td>The matter I raised on my end of the converati...</td>\n",
              "      <td>Purely to update: Tom had me in for lunch at t...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>[Purely to update: Tom had me in for lunch at ...</td>\n",
              "      <td>[2923, 4, 498, 37, 396, 49, 48, 8, 14, 726, 29...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>C05782457_0</td>\n",
              "      <td>arming the rebels, women, and small arms</td>\n",
              "      <td>Kavita Ramdas, until recently the head of the ...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>[Kavita Ramdas, until recently the head of the...</td>\n",
              "      <td>[6295, 6296, 3, 463, 790, 1, 614, 6, 1, 741, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>C05739879_1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I called PM el-Keib this morning to get his ta...</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[I called PM el-Keib this morning to get his t...</td>\n",
              "      <td>[11, 207, 318, 6320, 20, 6321, 17, 224, 4, 55,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>C05765100_1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Department of State Ranks High as Employer for...</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>[Department of State Ranks High as Employer fo...</td>\n",
              "      <td>[127, 6, 71, 6342, 6343, 25, 6344, 14, 558, 63...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>C05773055_1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Dear Hillary Wanted to take a minute to thank ...</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>[Dear Hillary Wanted to take a minute to thank...</td>\n",
              "      <td>[187, 285, 6364, 4, 115, 9, 2823, 4, 324, 16, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>C05784364_6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ambassador Siddique:\\n\\nGreat speaking with yo...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>[Ambassador Siddique:\\n\\nGreat speaking with y...</td>\n",
              "      <td>[168, 6374, 37, 7, 2691, 1229, 15, 16, 82, 2, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         text_id                                            subject  \\\n",
              "0    C05760125_1                        Hilda Solis Tom and Craig--   \n",
              "1    C05768263_2                                                NaN   \n",
              "2    C05771873_1                    Framing Statement - State Draft   \n",
              "3    C05768528_2                                                NaN   \n",
              "4    C05775052_1  The matter I raised on my end of the converati...   \n",
              "..           ...                                                ...   \n",
              "195  C05782457_0           arming the rebels, women, and small arms   \n",
              "196  C05739879_1                                                NaN   \n",
              "197  C05765100_1                                                NaN   \n",
              "198  C05773055_1                                                NaN   \n",
              "199  C05784364_6                                                NaN   \n",
              "\n",
              "                                                  text  ratingA1  ratingA2  \\\n",
              "0    Madame Secretary:\\n\\nThank you for reaching ou...         3         3   \n",
              "1    Cheryl, Jake,\\n\\nI received a call from Masood...         3         3   \n",
              "2    We anticipate the release of what are claimed ...         3         3   \n",
              "3    Spoke to Ed Levine today to follow up on Frida...         3         3   \n",
              "4    Purely to update: Tom had me in for lunch at t...         2         1   \n",
              "..                                                 ...       ...       ...   \n",
              "195  Kavita Ramdas, until recently the head of the ...         3         3   \n",
              "196  I called PM el-Keib this morning to get his ta...         2         3   \n",
              "197  Department of State Ranks High as Employer for...         2         3   \n",
              "198  Dear Hillary Wanted to take a minute to thank ...         2         3   \n",
              "199  Ambassador Siddique:\\n\\nGreat speaking with yo...         2         2   \n",
              "\n",
              "     ratingA3  labelA  ratingM1  ratingM2  ratingM3  ratingM4  ratingM5  \\\n",
              "0           3       3         2         3         2         2         2   \n",
              "1           3       3         2         2         2         3         2   \n",
              "2           3       3         3         2         3         2         1   \n",
              "3           3       3         3         2         2         1         3   \n",
              "4           3       2         2         2         3         1         2   \n",
              "..        ...     ...       ...       ...       ...       ...       ...   \n",
              "195         2       3         1         1         2         2         2   \n",
              "196         2       3         1         1         2         2         1   \n",
              "197         2       3         2         3         3         2         3   \n",
              "198         2       3         2         2         2         2         3   \n",
              "199         3       3         2         2         3         1         3   \n",
              "\n",
              "     labelM                                     sentences_list  \\\n",
              "0         2  [Madame Secretary:\\n\\nThank you for reaching o...   \n",
              "1         2  [Cheryl, Jake,\\n\\nI received a call from Masoo...   \n",
              "2         2  [We anticipate the release of what are claimed...   \n",
              "3         2  [Spoke to Ed Levine today to follow up on Frid...   \n",
              "4         2  [Purely to update: Tom had me in for lunch at ...   \n",
              "..      ...                                                ...   \n",
              "195       1  [Kavita Ramdas, until recently the head of the...   \n",
              "196       1  [I called PM el-Keib this morning to get his t...   \n",
              "197       3  [Department of State Ranks High as Employer fo...   \n",
              "198       2  [Dear Hillary Wanted to take a minute to thank...   \n",
              "199       2  [Ambassador Siddique:\\n\\nGreat speaking with y...   \n",
              "\n",
              "                                              encoding  \n",
              "0    [1046, 44, 37, 7, 320, 16, 14, 2848, 77, 4, 44...  \n",
              "1    [199, 3, 183, 3, 7, 11, 560, 9, 123, 33, 2877,...  \n",
              "2    [43, 2883, 1, 1061, 6, 78, 26, 1365, 4, 19, 40...  \n",
              "3    [2904, 4, 495, 2905, 82, 4, 445, 63, 13, 490, ...  \n",
              "4    [2923, 4, 498, 37, 396, 49, 48, 8, 14, 726, 29...  \n",
              "..                                                 ...  \n",
              "195  [6295, 6296, 3, 463, 790, 1, 614, 6, 1, 741, 1...  \n",
              "196  [11, 207, 318, 6320, 20, 6321, 17, 224, 4, 55,...  \n",
              "197  [127, 6, 71, 6342, 6343, 25, 6344, 14, 558, 63...  \n",
              "198  [187, 285, 6364, 4, 115, 9, 2823, 4, 324, 16, ...  \n",
              "199  [168, 6374, 37, 7, 2691, 1229, 15, 16, 82, 2, ...  \n",
              "\n",
              "[200 rows x 15 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smLVgYaakYvV"
      },
      "source": [
        "# GRU model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "7USorwoIokp4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import GRU\n",
        "from keras.layers import SimpleRNN\n",
        "from keras.layers import Embedding\n",
        "from keras.preprocessing import sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "17dg4rpmop0R"
      },
      "outputs": [],
      "source": [
        "np.random.seed(7)\n",
        "X_train = sequence.pad_sequences(train.data['encoding'],maxlen = 500)\n",
        "y_train = encoded#train.data['h_e']\n",
        "X_test = sequence.pad_sequences(test.data['encoding'],maxlen=500)\n",
        "y_test = t_encoded#test.data['h_e']\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNglJ5YJqIPd",
        "outputId": "da5c332e-38cf-47fc-f7f4-7b3de517f49c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/smruti/.local/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "Epoch 1/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 71ms/step - accuracy: 0.4351 - loss: 1.1449\n",
            "Epoch 2/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 70ms/step - accuracy: 0.5855 - loss: 0.9259\n",
            "Epoch 3/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 69ms/step - accuracy: 0.8943 - loss: 0.3608\n",
            "Epoch 4/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 70ms/step - accuracy: 0.9818 - loss: 0.0863\n",
            "Epoch 5/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 69ms/step - accuracy: 0.9922 - loss: 0.0369\n",
            "Epoch 6/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 70ms/step - accuracy: 0.9933 - loss: 0.0270\n",
            "Epoch 7/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 73ms/step - accuracy: 0.9949 - loss: 0.0165\n",
            "Epoch 8/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 83ms/step - accuracy: 0.9952 - loss: 0.0165\n",
            "Epoch 9/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 81ms/step - accuracy: 0.9940 - loss: 0.0150\n",
            "Epoch 10/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 82ms/step - accuracy: 0.9962 - loss: 0.0111\n",
            "Epoch 11/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 82ms/step - accuracy: 0.9919 - loss: 0.0312\n",
            "Epoch 12/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 80ms/step - accuracy: 0.9886 - loss: 0.0308\n",
            "Epoch 13/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 92ms/step - accuracy: 0.9906 - loss: 0.0276\n",
            "Epoch 14/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 87ms/step - accuracy: 0.9767 - loss: 0.0658\n",
            "Epoch 15/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 85ms/step - accuracy: 0.9877 - loss: 0.0358\n",
            "Epoch 16/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 86ms/step - accuracy: 0.9923 - loss: 0.0212\n",
            "Epoch 17/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 85ms/step - accuracy: 0.9940 - loss: 0.0137\n",
            "Epoch 18/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 100ms/step - accuracy: 0.9939 - loss: 0.0137\n",
            "Epoch 19/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 98ms/step - accuracy: 0.9946 - loss: 0.0127\n",
            "Epoch 20/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 100ms/step - accuracy: 0.9954 - loss: 0.0095\n",
            "Accuracy:  35.499998927116394\n"
          ]
        }
      ],
      "source": [
        "embedding_vector_length = 32\n",
        "model_RNN = Sequential()\n",
        "model_RNN.add(Embedding(40000,embedding_vector_length,input_length = 500))\n",
        "model_RNN.add(SimpleRNN(32,dropout=0.2, return_sequences = True ))\n",
        "model_RNN.add(SimpleRNN(32))\n",
        "model_RNN.add(Dense(4,activation = 'softmax'))\n",
        "model_RNN.compile(loss ='categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
        "print(model_RNN.summary())\n",
        "model_RNN.fit(X_train,y_train, epochs = 20, batch_size=23)\n",
        "\n",
        "scores = model_RNN.evaluate(X_test, y_test, verbose =0)\n",
        "print(\"Accuracy: \",(scores[1]*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4ChSeTplpM8",
        "outputId": "86971958-589f-4140-96a0-ff2b6dda6ae8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model_RNN.save(\"OUTPUT/RNN_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "-K_SWuGAecZg"
      },
      "outputs": [],
      "source": [
        "# import pickle\n",
        "# filename = 'model_1.sav'\n",
        "# pickle.dump(model,open(filename,'wb'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "B-LghG347Nr-"
      },
      "outputs": [],
      "source": [
        "# type(X_train)\n",
        "\n",
        "# X_train = np.append(train.data['similarity'][:,np.newaxis], X_train, axis=1)\n",
        "# X_test = np.append(test.data['similarity'][:,np.newaxis],X_test, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "-3lzA4pywwZ8"
      },
      "outputs": [],
      "source": [
        "coh_bin = []\n",
        "for i in range(4600):\n",
        "  if train.data['labelA'].tolist()[i] >=2:\n",
        "    coh_bin.append(1)\n",
        "  else:\n",
        "    coh_bin.append(0)\n",
        "train.data['bin_coh']= coh_bin\n",
        "\n",
        "\n",
        "coh_bin=[]\n",
        "for i in range(200):\n",
        "  if test.data['labelA'].tolist()[i] >=2:\n",
        "    coh_bin.append(1)\n",
        "  else:\n",
        "    coh_bin.append(0)\n",
        "\n",
        "test.data['bin_coh']=coh_bin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "7Q5r6H4yx3i_"
      },
      "outputs": [],
      "source": [
        "lst = array(train.data['bin_coh'])\n",
        "encoded = to_categorical(lst)\n",
        "\n",
        "lst = array(test.data['bin_coh'])\n",
        "t_encoded = to_categorical(lst)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "6dERcvIFyWF2"
      },
      "outputs": [],
      "source": [
        "np.random.seed(7)\n",
        "X_train = sequence.pad_sequences(train.data['encoding'],maxlen = 500)\n",
        "y_train = encoded#train.data['h_e']\n",
        "X_test = sequence.pad_sequences(test.data['encoding'],maxlen=500)\n",
        "y_test = t_encoded#test.data['h_e']\n",
        "\n",
        "# X_train = np.append(train.data['similarity'][:,np.newaxis], X_train, axis=1)\n",
        "# X_test = np.append(test.data['similarity'][:,np.newaxis],X_test, axis=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckWk6V9cyfWY",
        "outputId": "30ecc132-440d-44fd-8787-67cf22f5c161"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/smruti/.local/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_2 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_3 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "Epoch 1/15\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 80ms/step - accuracy: 0.6506 - loss: 0.6552\n",
            "Epoch 2/15\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 83ms/step - accuracy: 0.7734 - loss: 0.4767\n",
            "Epoch 3/15\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 84ms/step - accuracy: 0.9748 - loss: 0.1043\n",
            "Epoch 4/15\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 81ms/step - accuracy: 0.9950 - loss: 0.0261\n",
            "Epoch 5/15\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 80ms/step - accuracy: 0.9973 - loss: 0.0124\n",
            "Epoch 6/15\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 88ms/step - accuracy: 0.9975 - loss: 0.0104\n",
            "Epoch 7/15\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 88ms/step - accuracy: 0.9978 - loss: 0.0097\n",
            "Epoch 8/15\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 99ms/step - accuracy: 0.9953 - loss: 0.0131\n",
            "Epoch 9/15\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 98ms/step - accuracy: 0.9955 - loss: 0.0185\n",
            "Epoch 10/15\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 98ms/step - accuracy: 0.9950 - loss: 0.0178\n",
            "Epoch 11/15\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 99ms/step - accuracy: 0.9976 - loss: 0.0073\n",
            "Epoch 12/15\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 98ms/step - accuracy: 0.9952 - loss: 0.0120\n",
            "Epoch 13/15\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 103ms/step - accuracy: 0.9978 - loss: 0.0060\n",
            "Epoch 14/15\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 100ms/step - accuracy: 0.9953 - loss: 0.0093\n",
            "Epoch 15/15\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 98ms/step - accuracy: 0.9958 - loss: 0.0071\n",
            "Accuracy:  63.999998569488525\n"
          ]
        }
      ],
      "source": [
        "embedding_vector_length = 32\n",
        "model_RNN_B = Sequential()\n",
        "model_RNN_B.add(Embedding(40000,embedding_vector_length,input_length = 500))\n",
        "model_RNN_B.add(SimpleRNN(32,dropout=0.2, return_sequences = True ))\n",
        "model_RNN_B.add(SimpleRNN(32))\n",
        "model_RNN_B.add(Dense(2,activation = 'softmax'))\n",
        "model_RNN_B.compile(loss ='binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
        "print(model_RNN_B.summary())\n",
        "model_RNN_B.fit(X_train,y_train, epochs = 15 , batch_size=23)\n",
        "\n",
        "scores = model_RNN_B.evaluate(X_test, y_test, verbose =0)\n",
        "print(\"Accuracy: \",(scores[1]*100))\n",
        "\n",
        "\n",
        "# embedding_vector_length = 32\n",
        "# model_RNN = Sequential()\n",
        "# model_RNN.add(Embedding(40000,embedding_vector_length,input_length = 500))\n",
        "# model_RNN.add(SimpleRNN(32,dropout=0.2, return_sequences = True ))\n",
        "# model_RNN.add(SimpleRNN(32))\n",
        "# model_RNN.add(Dense(4,activation = 'softmax'))\n",
        "# model_RNN.compile(loss ='categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
        "# print(model_RNN.summary())\n",
        "# model_RNN.fit(X_train,y_train, epochs = 20, batch_size=23)\n",
        "\n",
        "# scores = model_RNN.evaluate(X_test, y_test, verbose =0)\n",
        "# print(\"Accuracy: \",(scores[1]*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrMabokCquxC",
        "outputId": "759c82e7-8643-406e-bf66-be1491a1c2da"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model_RNN_B.save(\"OUTPUT/RNN_model_B.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "eQgrSud3uSdc"
      },
      "outputs": [],
      "source": [
        "train.data = similarity_paragraph(train.data)\n",
        "test.data = similarity_paragraph(test.data)\n",
        "\n",
        "len(train_mapping)\n",
        "# train_mapping\n",
        "train.data['encoding'] = train_mapping\n",
        "test.data['encoding'] = test_mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBwN9V5MrslM",
        "outputId": "bd2d805a-a4f8-4ba1-e7a7-91184d2f633c"
      },
      "outputs": [],
      "source": [
        "np.random.seed(7)\n",
        "X_train = sequence.pad_sequences(train.data['encoding'],maxlen = 500)\n",
        "y_train = encoded#train.data['h_e']\n",
        "X_test = sequence.pad_sequences(test.data['encoding'],maxlen=500)\n",
        "y_test = t_encoded#test.data['h_e']\n",
        "\n",
        "# X_train = X_train.reshape(4600,500,1)\n",
        "# X_test = X_test.reshape(200,500,1)\n",
        "\n",
        "# print(X_train.shape)\n",
        "# print(train.data['similarity'].shape)\n",
        "\n",
        "# X_train = np.append(train.data['similarity'], X_train, axis=0)\n",
        "# # X_test = np.append(test.data['similarity'],X_test, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQyQmJV5rtY5",
        "outputId": "b3050ecc-1356-4824-9525-a1404c22e42f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/smruti/.local/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_4 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_5 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "Epoch 1/15\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 73ms/step - accuracy: 0.6573 - loss: 0.6396\n",
            "Epoch 2/15\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 73ms/step - accuracy: 0.7588 - loss: 0.4929\n",
            "Epoch 3/15\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - accuracy: 0.9665 - loss: 0.1325\n",
            "Epoch 4/15\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 73ms/step - accuracy: 0.9890 - loss: 0.0385\n",
            "Epoch 5/15\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 82ms/step - accuracy: 0.9962 - loss: 0.0189\n",
            "Epoch 6/15\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 85ms/step - accuracy: 0.9971 - loss: 0.0141\n",
            "Epoch 7/15\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 100ms/step - accuracy: 0.9986 - loss: 0.0067\n",
            "Epoch 8/15\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 95ms/step - accuracy: 0.9969 - loss: 0.0098\n",
            "Epoch 9/15\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 93ms/step - accuracy: 0.9948 - loss: 0.0141\n",
            "Epoch 10/15\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 94ms/step - accuracy: 0.9934 - loss: 0.0152\n",
            "Epoch 11/15\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 93ms/step - accuracy: 0.9916 - loss: 0.0205\n",
            "Epoch 12/15\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 101ms/step - accuracy: 0.9980 - loss: 0.0071\n",
            "Epoch 13/15\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 99ms/step - accuracy: 0.9962 - loss: 0.0079\n",
            "Epoch 14/15\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 98ms/step - accuracy: 0.9975 - loss: 0.0055\n",
            "Epoch 15/15\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 97ms/step - accuracy: 0.9975 - loss: 0.0056\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f37dbd3d3d0>"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding_vector_length = 32\n",
        "model_RNN_C = Sequential()\n",
        "model_RNN_C.add(Embedding(40000,embedding_vector_length,input_length = 501))\n",
        "model_RNN_C.add(SimpleRNN(32,dropout=0.2, return_sequences = True ))\n",
        "model_RNN_C.add(SimpleRNN(32))\n",
        "model_RNN_C.add(Dense(2,activation = 'softmax'))\n",
        "model_RNN_C.compile(loss ='binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
        "print(model_RNN_C.summary())\n",
        "model_RNN_C.fit(X_train,y_train, epochs = 15 , batch_size=23)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2uCC98B3zkM",
        "outputId": "492cabaa-7610-45fc-81e8-4eb4ea9be3ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  57.999998331069946\n"
          ]
        }
      ],
      "source": [
        "scores = model_RNN_C.evaluate(X_test, y_test, verbose =0)\n",
        "print(\"Accuracy: \",(scores[1]*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-m24eY_Nrx-d",
        "outputId": "b3525427-b587-49cc-8cf9-0e1d67903bf9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model_RNN_C.save(\"OUTPUT/RNN_model_C.h5\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Textual_Coherence_RNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
